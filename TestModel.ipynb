{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a4e3d69-4412-47c4-8ea4-e758740f2839",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e5833454-23e5-4962-a2b2-54a6d833252c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba9d65feb75543819d9b9862003ad368",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\"./llama2-chat-guanaco-databricks\").cuda(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "860aee3a-10ad-4bae-83c5-4fc6ab395ceb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"./llama2-chat-guanaco-databricks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dcaef583-67fe-4bc6-9ed2-19fdbdd35505",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LlamaForCausalLM(\n",
       "  (model): LlamaModel(\n",
       "    (embed_tokens): Embedding(32001, 4096)\n",
       "    (layers): ModuleList(\n",
       "      (0-31): 32 x LlamaDecoderLayer(\n",
       "        (self_attn): LlamaAttention(\n",
       "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "          (up_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "          (down_proj): Linear(in_features=11008, out_features=4096, bias=False)\n",
       "          (act_fn): SiLUActivation()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm()\n",
       "        (post_attention_layernorm): LlamaRMSNorm()\n",
       "      )\n",
       "    )\n",
       "    (norm): LlamaRMSNorm()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=4096, out_features=32001, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b2af2eea-414c-4234-895a-c1e80ca62891",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT_DICT = {\n",
    "    \"prompt_input\": (\n",
    "        \"Below is an instruction that describes a task, paired with an input that provides further context. \"\n",
    "        \"Write a response that appropriately completes the request.\\n\\n\"\n",
    "        \"### Instruction:\\n{instruction}\\n\\n### Input:\\n{input}\\n\\n### Response:\"\n",
    "    ),\n",
    "    \"prompt_no_input\": (\n",
    "        \"Below is an instruction that describes a task. \"\n",
    "        \"Write a response that appropriately completes the request.\\n\\n\"\n",
    "        \"### Instruction:\\n{instruction}\\n\\n### Response:\"\n",
    "    ),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e68232fe-9659-4dec-a51e-2cf5ec978dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "仕事の熱意を取り戻すためのアイデアを5つ挙げてください。\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "330b3e0e-11e8-4bfc-885b-25134519e18b",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_k = 50\n",
    "top_p = 0.95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dbcaed9b-bf9e-429a-8497-e8760ba81351",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "'Below is an instruction that describes a task. Write a response that appropriately completes the request.\\n\\n### Instruction:\\n\\n仕事の熱意を取り戻すためのアイデアを5つ挙げてください。\\n\\n\\n### Response:'"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = PROMPT_DICT[\"prompt_no_input\"].format(instruction=prompt)\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "91f8a3dc-6d64-489b-9e03-3bc226c6513f",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer.encode(prompt, return_tensors=\"pt\", max_length=2048, truncation=True).to(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "58947991-548a-4192-83f4-2411d9f3de38",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = model.generate(inputs, max_length=2048, num_return_sequences=1, pad_token_id=tokenizer.eos_token_id, top_k=top_k, top_p=top_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f38e8acc-9787-41ba-b681-bab11a805b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "generated = tokenizer.decode(outputs[0], skip_special_tokens=True)[len(prompt):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "94b614a0-e549-4c7f-8d1f-8a134607c14f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1. 目標に向けて努力する。\n",
      "2. 新しい職場での課題に挑戦する。\n",
      "3. 仕事の快適性を高めるために、休日を休まない。\n",
      "4. 仕事の熱意を取り戻すために、働き方を変える。\n",
      "5. 仕事に情熱を持っている人を見つけ、彼らの姿勢に学びましょう。\n"
     ]
    }
   ],
   "source": [
    "print(generated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a5f1a0-e7bf-4d34-9545-a66d59965e3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c35962-3ae5-4acf-9194-244557a70dd2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
